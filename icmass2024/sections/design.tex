\section{Sensor Rig Design}
The sensor rig is designed to carried and operated by a single person, but can also be attached to a vessel.
Two 1m carbon fiber tubes servs as the main structure and provides rigidity to the rig without adding much weight.
Except for the waterproof enclosure and the two carbon fiber tubes, all the mechanical parts are 3D printed, making the sensor rig easy to reproduce and modify.
The various parts are designed to clamp on to the 30mm carbon fiber tubes and friction tape is used to ensure a tight fit.
This makes it easy to extend the rig with additional sensors or design various clamping brackets for attaching the rig to different vessels.
An IP67 rated waterproof enclosure is used to protect the internal electronics from the elements, allowing for operation in different weather conditions.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/rig_components.pdf}
    \caption{Cad model of the sensor rig with the enclosure removed for visibility.}
\end{figure}

\subsection{Components}
One TRI050S1-QC polarization camera and one TOP106 L1/L2 GNSS antenna is mounted on each side of the sensor rig to provide wide baseline stereo video and differential GNSS data for accurate heading estimation.
The cameras have a 2/3" global shutter sensor with a $2448\times2048$ resolution, are equipped with a 8mm lense, and configured to capture 12-bit raw images at 12fps.
Inside the waterproof enclosure an Nvidia Jetson Orin AGX serves as the main processing unit.
The Jetson is a single board computer designed for edge computing with a dedicated GPU, GPIO and multiple dedicated hardware for video processing and AI \cite{karumbunathanNVIDIAJetsonAGX2022}.
An external network card is connected to the Jetson through its PCIe slot and provedes 4 separate 1Gb/s ethernet ports with \gls{poe} to power and communicate with the cameras over a single cable.
Two F9P GNSS receivers and a STIM300 \gls{imu} provide the sensor data required for accurate pose estimation.
With a 100wh power bank, the sensor rig can record data for approximately 5 hours before needing a battery change.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/operation.jpg}
    \caption{Human operation of the sensor rig. Ergonomic handles ensure comfort and the operator can control and monitor the acquisition through a phone over the phone's mobile hotspot. \label{fig:operation}}
\end{figure}

\subsection{Control and Monitoring}
The sensor rig hosts a web app that allows the operator to control and monitor the data acquisition from their smartphone, as depicted in Figure \ref{fig:operation}.
The web app is built with SvelteKit and communicates with the different programs running on the Jetson through websockets.
From the app the operator can start and stop the aquisition, incoming data from the different sensors and view a live stream from the cameras.
The app also provides information from the Jetson such as CPU temperature, storage usage, \gls{pps} status and battery voltage.
Earlier versions of the app alowed the user to configure parameters such as exposure and gain but we noticed that this took away focus so we swithed to automatic adjustment of these parameters.
Having a simple interface makes it possible for almost anyone to use the sensor rig and adds to its usability.


\subsection{Synchronization}
Emphasis has been put on accurately synchronizing all sensors on the sensor rig to \gls{utc}.
The \gls{gnss} receivers are synchronized to \gls{utc} by them selves, and does not require further synchronization.
The \gls{imu} samples at a fixed frequency following an internal clock \cite{safranSTIM300Datasheet}.
When it receives a trigger signal it sends the latest available data, together with the trigger count and the delay between the latest message and the trigger \cite{safranSTIM300Datasheet}.
To synchronize the \gls{imu} to \gls{utc} we use a Raspberry Pi Pico microcontroller to periodically route the trigger signal to the \gls{imu} and the \gls{f9p} receiver simultaneously, causing the \gls{f9p} to log a time mark message we use to stamp the \gls{imu} data \cite[190]{u-bloxZEDF9PInterfaceDescription}.
The cameras and the network card all support \gls{ptp}, making it possible to synchronize the cameras to the clock on the Jetson.
Using an oscilloscope we measured the synchronization error between the cameras to be below $20\mu s$ by comparing the trigger signal emitted from the cameras.
The final step in the syndhronization process is to synchronize the Jetson to \gls{utc} using the \gls{pps} signal from one of the \gls{f9p} receivers.
This requiered making several modification to, and compiling, the linux kernel running on the Jetson, which took considerable time and effort.
A script that downloads, modifies and compiles all the necessary files is available on request.
The reported accuracy of the \gls{pps} synchronization is reported to be approximately $4\mu s$.







